{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "\t# take a bounding predicted by dlib and convert it\n",
    "\t# to the format (x, y, w, h) as we would normally do\n",
    "\t# with OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\t# return a tuple of (x, y, w, h)\n",
    "\treturn (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# initialize the list of (x, y)-coordinates\n",
    "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
    "\t# loop over the 68 facial landmarks and convert them\n",
    "\t# to a 2-tuple of (x, y)-coordinates\n",
    "\tfor i in range(0, 68):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\t# return the list of (x, y)-coordinates\n",
    "\treturn coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"trump.jpg\")\n",
    "image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, rect) in enumerate(rects):\n",
    "\t# determine the facial landmarks for the face region, then\n",
    "\t# convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "\t# array\n",
    "\tshape = predictor(gray, rect)\n",
    "\tshape = face_utils.shape_to_np(shape)\n",
    "\t# convert dlib's rectangle to a OpenCV-style bounding box\n",
    "\t# [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "\t(x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\t# show the face number\n",
    "\tcv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\t# loop over the (x, y)-coordinates for the facial landmarks\n",
    "\t# and draw them on the image\n",
    "\tfor (x, y) in shape:\n",
    "\t\tcv2.circle(image, (x, y), 1, (0, 0, 255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp, AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AffineTransform()\n",
    "model.estimate(shape, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AffineTransform(matrix=\n",
       "    [[ 1.00000000e+00, -3.16909077e-16,  2.84217094e-14],\n",
       "     [-2.15161498e-18,  1.00000000e+00,  2.84217094e-14],\n",
       "     [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]) at 0x7fe32575e8b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust, inliers = ransac((shape[:5], shape[10:15]), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8063851419292324, 0.8973723910733196) [365.93277443 296.86158409] -2.532965807504927\n"
     ]
    }
   ],
   "source": [
    "print(model_robust.scale, model_robust.translation, model_robust.rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.round(model.scale)\n",
    "t = np.round(model.translation)\n",
    "r = np.round(model.rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1.]), array([0., 0.]), -0.0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, t, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = AffineTransform(scale=s, rotation = r,translation=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AffineTransform(matrix=\n",
       "    [[ 1., -0.,  0.],\n",
       "     [-0.,  1.,  0.],\n",
       "     [ 0.,  0.,  1.]]) at 0x7fe32575eca0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape2 = warp(shape, tform.inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.39066579e-17, 1.54498810e-17]), array([220, 142]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape2[5], shape[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
