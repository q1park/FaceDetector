{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from typing import List\n",
    "\n",
    "def get_frame_idx(fname: str) -> int:\n",
    "    \"\"\"for a given file name, return the frame index.\n",
    "    \n",
    "    for example, 'cropped/001.png' returns int 1.\n",
    "    \"\"\"\n",
    "    idx = int(fname.split(\"/\")[-1].split(\".\")[0])\n",
    "    return idx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_blocks(stack: List[str]) -> List[List[int]]:\n",
    "    \"\"\"create continguous blocks of similar frames.\n",
    "    \"\"\"\n",
    "    MAX_FRAME_DIFF = 5\n",
    "\n",
    "    blocks = []\n",
    "    block = []\n",
    "\n",
    "    for i in range(len(stack) - 1):\n",
    "        p_idx = frame(stack[i])\n",
    "        n_idx = frame(stack[i + 1])\n",
    "\n",
    "        if (n_idx - p_idx) < MAX_FRAME_DIFF:\n",
    "            block.append(p_idx)\n",
    "            block.append(n_idx)\n",
    "        else:\n",
    "            blocks.append(block)\n",
    "            block = []\n",
    "            \n",
    "    return blocks\n",
    "\n",
    "\n",
    "\n",
    "def create_snippets(video: List[str]) -> List[str]:\n",
    "    \"\"\"generate continguous snippets from a list of frames.\n",
    "    \n",
    "    snippets are frames that are separated by no more than MAX_FRAME_DIFF.\n",
    "    \"\"\"\n",
    "    MAX_FRAME_DIFF = 5\n",
    "\n",
    "    blocks = []\n",
    "    block = []\n",
    "\n",
    "    for i in range(len(video) - 1):\n",
    "        p_idx = get_frame_idx(video[i])\n",
    "        n_idx = get_frame_idx(video[i + 1])\n",
    "\n",
    "        if (n_idx - p_idx) < MAX_FRAME_DIFF:\n",
    "            block.append(video[i])\n",
    "            block.append(video[i + 1])\n",
    "        else:\n",
    "            if len(block) > 0:\n",
    "                blocks.append(sorted(list(set(block))))\n",
    "            block = []\n",
    "    blocks.append(sorted(list(set(block))))\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def split_files_by_actors(folder: str, label: str) -> dict:\n",
    "    \"\"\"separate images by actor.\n",
    "    \n",
    "    a folder contains images from multiple actors. we will separate images by actor.\n",
    "    \"\"\"\n",
    "    \n",
    "    fnames = sorted(glob(folder + '/' + label + '/*'))\n",
    "\n",
    "    actor_ids = _get_actor_ids(folder, label)  # get all possible IDs for a given folder\n",
    "    \n",
    "    fnames_by_actor = {}\n",
    "    for actor in actor_ids:\n",
    "        fnames_by_actor[actor] = []\n",
    "    \n",
    "    for actor in actor_ids:\n",
    "        for fname in fnames:\n",
    "            actor_id = int(fname.split(\".\")[-2])\n",
    "            if actor_id == actor:\n",
    "                fnames_by_actor[actor].append(fname)\n",
    "    return fnames_by_actor\n",
    "\n",
    "\n",
    "def _get_actor_ids(folder: str, label: str) -> List:\n",
    "    fnames = sorted(glob(folder + '/' + label + '/*'))\n",
    "    \n",
    "    actor_ids = []\n",
    "    for fname in fnames:\n",
    "        actor_id = int(fname.split(\".\")[-2])\n",
    "        if actor_id not in actor_ids:\n",
    "            actor_ids.append(actor_id)\n",
    "    return actor_ids\n",
    "\n",
    "\n",
    "def remove_outliers_from_snippet(files: List[str]) -> List[str]:\n",
    "    \"\"\"remove images that are not similar with any other images in the batch.\n",
    "    \n",
    "    files is a sorted list of image file names, sorted by frame index number. this helps us\n",
    "    keep files that are similar to its neighbors.\n",
    "\n",
    "    we want to keep images that are similar with at least one other image in the batch.\n",
    "    this is because we want to find long contiguous blocks of similar images, which would\n",
    "    suggest static faces.\n",
    "    \"\"\"\n",
    "    \n",
    "    stack = []\n",
    "    \n",
    "    # remove other images\n",
    "\n",
    "    for i in range(len(files) - 1):\n",
    "        prev_f = files[i]\n",
    "        next_f = files[i + 1]\n",
    "\n",
    "        prev_h = imagehash.average_hash(Image.open(prev_f))\n",
    "        next_h = imagehash.average_hash(Image.open(next_f))\n",
    "\n",
    "        # keep if it's similar\n",
    "        if next_h == prev_h:\n",
    "            stack.append(prev_f)\n",
    "            stack.append(next_f)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return sorted(list(set(stack)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/547538174468711490516541559363']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get folders\n",
    "folders = glob(\"dataset/*\")\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for that folder, look at static label\n",
    "collection_by_actor = split_files_by_actors(folder = folders[0], label = \"static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_by_id = collection_by_actor[1]  # all videos by actor id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/547538174468711490516541559363/static/00224.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00228.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00232.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00236.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00240.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00244.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00248.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00252.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00256.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00260.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00264.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00268.00001.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets = create_snippets(videos_by_id)  # snippets without outliers removed\n",
    "snippets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/547538174468711490516541559363/static/00228.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00232.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00236.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00240.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00244.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00248.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00252.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00256.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00260.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00264.00001.jpg',\n",
       " 'dataset/547538174468711490516541559363/static/00268.00001.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_snippets = remove_outliers_from_snippet(snippets[0])\n",
    "processed_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dataset/547538174468711490516541559363/static/00228.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00232.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00236.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00240.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00244.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00248.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00252.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00256.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00260.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00264.00001.jpg',\n",
       "  'dataset/547538174468711490516541559363/static/00268.00001.jpg']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_snippets(processed_snippets)  # recreate snippets now that outliers have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
